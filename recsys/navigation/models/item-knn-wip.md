# item KNN \[WIP]

## item KNN \[WIP]

KNN — модель ближайших соседей.

1. Создается матрица взаимодействий с ключами (User-Item) и значением взаимодействия с объектом.
2. Ищутся схожие вектора относительно (user-user) или (item-item) на метриках схожести косинусное расстояние или корреляция Пирсона, и тд.

***

### Как работает KNN

Представим что у нас существует некоторая матрица I объектов на J товаров

|        | item 1 | item 2 | … | item j |
| ------ | ------ | ------ | - | ------ |
| user 1 | 1      | 0      | … | 1      |
| user 2 | 1      | 1      | … | 1      |
| …      | …      | …      | … | …      |
| user i | nan    | nan    | … | 1      |

#### Item KNN

1. **Вычисление схожести между товарами**: Для каждой пары товаров вычислите меру схожести. Обычно используют косинусное сходство, корреляцию Пирсона, Jaccard similarity или другие метрики.
2. **Выбор K ближайших товаров**: Для каждого товара выберите K наиболее похожих товаров.
3. **Прогнозирование оценки**: Для пользователя, который не оценивал товар, можно предсказать его оценку, основываясь на оценках этого пользователя для K ближайших товаров.

**Например:**

$cos(item\_1, item\_2) = 0.5$

$cos(item\_j, item\_1) = 0.9$

$cos(item\_j, item\_2) = 0.5$

**Недостатки метода:**

Как мы можем заметить мы не учитваем схожести относительно взаимодействий юзера, исходя из чего рекомендации сильно проседают

#### User KNN

1. **Вычисление схожести между пользователями**: Для каждой пары пользователей вычислите меру схожести. Как и в случае с Item KNN, для этого могут использоваться различные метрики.
2. **Выбор K ближайших пользователей**: Для каждого пользователя находите K наиболее похожих на него пользователей.
3. **Прогнозирование оценки**: Оценка товара, которую пользователь еще не видел, предсказывается на основе оценок этого товара пользователями из группы K ближайших соседей.

#### Модификация TF-IDF

После того как получаем схожих пользователей и товаров которые юзер не видел. Получается, что для одного _**user\_id**_ и его рекомендованных _**item\_id**_, пришедших от одного и того же соседа **мы имеем одну и ту же меру похожести** (_**similarity**_) просто потому, что так работает алгоритм.

Давайте это исправим на следующем шаге, посчитаем IDF для каждого item

* `n` - кол-во рекомендаций = кол-во пользователей
* `document frequency (= recommendation list frequency) of the item` = кол-во раз, когда item встречается в датафрейме с рекомендациями

```python
from collections import Counter
cnt = Counter(train['item_id'].values)

idf = pd.DataFrame.from_dict(cnt, orient='index', columns=['df']).reset_index()

n = train.shape[0]
idf['idf'] = idf['df'].apply(lambda x: np.log((1 + n) / (1 + x) + 1))

idf.head()
```

Далее полученные веса **IDF** просто джоиним на имеющуюся user-KNN. И просто домножаем _**similarity**_ на _**idf → rank\_idf**_

***

## Дополнительные ссылки

[https://github.com/sharthZ23/itmo\_recsys\_2023\_autumn/tree/main/Lecture 3. Baselines and kNN](https://github.com/sharthZ23/itmo\_recsys\_2023\_autumn/tree/main/Lecture%203.%20Baselines%20and%20kNN)
