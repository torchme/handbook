# The Alternating Least Squares Method \[WIP]

## Основная идея

**Alternative Least Squares (ALS)** — это метод матричной факторизации, который достаточно часто применяется в рекомендательных системах.

Представьте себе, что у вас есть огромная матрица (таблица) с оценками пользователей на различные продукты в некотором сервисе. Так вот ALS помогает разбить нашу матрицу на простые компоненты.

***

## Интуиция

Помните формулу суммы квадраты? Так вот интуитивна у нас будет такая же идея. У нас есть наша огромная user-item таблица назовем ее x, тогда квадрат суммы некоторых переменных a и b даст нам квадрат x.

$$
x^{2} = a^{2} + b^{2}
$$

***

***

## Функция оценки

$f\_{ui}: Users \* Items → Relevance$

Матрица оценок (действительные) будет равна $R\_{ui}$, где u - пользователи (users), i - объекты (items). Тогда перемножения векторов будет равно восстановленной матрицы $R\`$, которая аппроксимирует $R$ и равна перемножению $P$ и $Q^T$. В случае ALS, мы инициализируем матрицы случайными числами и поочередно оптимизируем матрицы $P$ и $Q^T$.

$r\_{ij}$ — какой-либо факт взаимодействия \[0; 1]

***

## Лосс функция

Вектора получаем за счет фиксирования какой-либо функции оценки и решения задач оптимизации. Другими словами насколько $R$ и $R\`$ близки друг к другу.

$L(R, R\`) → min$

$L = \sum\_{u,i}{c\_{ui}(r\_{ui} - p\_u \* q\_i^T)^2 + \lambda (\sum\_{u}||p\_u||^2 + \sum\_{i}||q\_i||^2)}$

Где $c\_{ui}$ — степень уверенности не меньше 1. (Матрица R)

***

### Разбираемся с формулой

Давайте немного разберемся с формулой, на самом деле она проще чем кажется

$\sum\_{u,i}{c\_{ui}(r\_{ui} - p\_u \* q\_i^T)^2}$

Тут мы просто вычитаем $r\_{ui}$, которая является некоторым фактическим значением и $r\`_{ui}$, и является предсказанием и перемножением матриц юзера и объекта из векторов $P$ и $Q^T$, а так же просто усиливаем это параметром $c_{ui}$. А так же делаем это поочередно сначала оптимизируем одну матрицу, потом вторую.

### Интуиция

Что по факту является MSE \~ $\sum{(y\_{\text{true\}} - y\_{\text{pred\}})^2}$,

***

### Вторая часть формулы

Вторая часть формулы на самом деле еще проще, это просто на всего $L\_1$, $L\_2$ [регуляризация](https://ru.wikipedia.org/wiki/%D0%A0%D0%B5%D0%B3%D1%83%D0%BB%D1%8F%D1%80%D0%B8%D0%B7%D0%B0%D1%86%D0%B8%D1%8F\_\(%D0%BC%D0%B0%D1%82%D0%B5%D0%BC%D0%B0%D1%82%D0%B8%D0%BA%D0%B0\))

$\lambda (\sum\_{u}||p\_u||^2 + \sum\_{i}||q\_i||^2)$

### Интуиция

Это просто штраф модели за слишком большие коэффициенты, что бы модель просто не заучила какой-то паттерн рекомендаций

### Матричное представление лосс функции

***

## Ключевые параметры модели

### Factors

Это размерность **векторного представления** **(k)** см. рис 1 **матрицы векторов пользователя (P)** и **матрицы векторов объекта (Q).**

_Обычно в диапазоне 16 и 256_

### Iterations

Количество прохождений по матрице P и Q

_Обычно в диапазоне 10 и 200_

### Regularization

Коэффициент регуляризации

_Обычно в диапазоне 0.0001 и 1_

***

## Дополнительные ссылки

[https://rectools.readthedocs.io/en/stable/api/rectools.models.implicit\_als.ImplicitALSWrapperModel.html](https://rectools.readthedocs.io/en/stable/api/rectools.models.implicit\_als.ImplicitALSWrapperModel.html)

[https://www.youtube.com/watch?v=GC0K27AZ\_Pg](https://www.youtube.com/watch?v=GC0K27AZ\_Pg)

[https://d2l.ai/chapter\_recommender-systems/mf.html](https://d2l.ai/chapter\_recommender-systems/mf.html)
